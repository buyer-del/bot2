# ============================================
#  üîä –ê—É–¥—ñ–æ ‚Üí Google Speech-to-Text (uk-UA)
#  üñºÔ∏è –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è ‚Üí Google Vision API (OCR)
#  üß† –ê–Ω–∞–ª—ñ–∑ –∑–∞–¥–∞—á ‚Üí Vertex AI (Gemini)
# ============================================

import os
import io
import json
import subprocess
import tempfile
import traceback
from typing import Optional

from google.cloud import speech_v1 as speech
from google.cloud import vision
import vertexai
from vertexai.generative_models import GenerativeModel, GenerationConfig


# -----------------------------
# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è Google Credentials
# -----------------------------
def _setup_google_credentials() -> str:
    """–°—Ç–≤–æ—Ä—é—î —Ç–∏–º—á–∞—Å–æ–≤–∏–π credentials.json –∑ GOOGLE_CREDENTIALS_JSON"""
    google_creds_json = os.environ.get("GOOGLE_CREDENTIALS_JSON")
    if not google_creds_json:
        raise ValueError("‚ùå GOOGLE_CREDENTIALS_JSON –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —É –∑–º—ñ–Ω–Ω–∏—Ö —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞!")

    creds_path = "/tmp/google_credentials.json"
    with open(creds_path, "w", encoding="utf-8") as f:
        f.write(google_creds_json)

    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = creds_path
    return creds_path


_CREDS_PATH = _setup_google_credentials()

# -----------------------------
# –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏
# -----------------------------
SPEECH_LANGUAGE = os.getenv("SPEECH_LANGUAGE", "uk-UA")

# -----------------------------
# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –∞—É–¥—ñ–æ ‚Üí WAV 16kHz mono
# -----------------------------
def _convert_to_wav_16k_mono(input_path: str) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç—É—î –±—É–¥—å-—è–∫–µ –∞—É–¥—ñ–æ/–≤—ñ–¥–µ–æ —É WAV PCM 16-bit, mono, 16000 Hz (—á–µ—Ä–µ–∑ ffmpeg)."""
    fd, out_path = tempfile.mkstemp(suffix=".wav")
    os.close(fd)
    cmd = [
        "ffmpeg", "-hide_banner", "-loglevel", "error",
        "-y", "-i", input_path, "-vn",
        "-ac", "1", "-ar", "16000", "-sample_fmt", "s16", out_path,
    ]
    try:
        subprocess.run(cmd, check=True)
    except subprocess.CalledProcessError as e:
        if os.path.exists(out_path):
            os.remove(out_path)
        raise RuntimeError(f"ffmpeg: –ø–æ–º–∏–ª–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó ({e})")
    return out_path


# -----------------------------
# Google Speech-to-Text
# -----------------------------
def transcribe_audio(input_path: str) -> Optional[str]:
    wav_path = None
    try:
        wav_path = _convert_to_wav_16k_mono(input_path)
        with open(wav_path, "rb") as f:
            content = f.read()

        audio = speech.RecognitionAudio(content=content)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,
            language_code=SPEECH_LANGUAGE,
            enable_automatic_punctuation=True,
            model="latest_long",
        )

        client = speech.SpeechClient()
        response = client.recognize(config=config, audio=audio)
        if not response.results:
            return None

        text = " ".join(
            r.alternatives[0].transcript.strip()
            for r in response.results
            if r.alternatives
        )
        return text or None
    except Exception:
        return None
    finally:
        if wav_path and os.path.exists(wav_path):
            try:
                os.remove(wav_path)
            except Exception:
                pass


# -----------------------------
# Google Vision OCR
# -----------------------------
def extract_text_from_image(image_path: str) -> Optional[str]:
    try:
        client = vision.ImageAnnotatorClient()
        with open(image_path, "rb") as img:
            content = img.read()
        image = vision.Image(content=content)
        response = client.text_detection(image=image)
        if response.error.message:
            raise RuntimeError(f"Vision API error: {response.error.message}")
        if not response.text_annotations:
            return None
        return (response.text_annotations[0].description or "").strip()
    except Exception:
        return None


# -----------------------------
# Vertex AI (Gemini) ‚Äî –∞–Ω–∞–ª—ñ–∑ –∑–∞–¥–∞—á
# -----------------------------
def analyze_task_with_ai(prompt: str, raw_text: str, timeout_sec: int = 20) -> Optional[str]:
    """–í–∏–∫–ª–∏–∫–∞—î Gemini-–º–æ–¥–µ–ª—å Vertex AI —ñ –ø–æ–≤–µ—Ä—Ç–∞—î —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å."""
    try:
        vertexai.init(project="task-dispatcher-bot", location="us-central1")
        model = GenerativeModel("gemini-1.5-flash")

        system_prompt = (
            prompt
            + "\n\n–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é. "
            + "–ü–æ–≤–µ—Ä–Ω–∏ –ª–∏—à–µ –ø'—è—Ç—å —Ä—è–¥–∫—ñ–≤ —Å—Ç—Ä–æ–≥–æ —É —Ñ–æ—Ä–º—ñ:\n"
            + "–ù–∞–∑–≤–∞: ...\n–¢–µ–≥: ...\n–î–µ–¥–ª–∞–π–Ω: ...\n–ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç: ...\n–û–ø–∏—Å: ..."
        )

        generation_config = GenerationConfig(
            temperature=0.2,
            top_p=0.9,
            max_output_tokens=512,
        )

        parts = [
            {"role": "user", "parts": [system_prompt]},
            {"role": "user", "parts": [f"–ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è:\n{raw_text}"]},
        ]

        # ‚úÖ –ü—Ä–∏–±—Ä–∞–Ω–æ timeout –ø–∞—Ä–∞–º–µ—Ç—Ä ‚Äî –Ω–µ –ø—ñ–¥—Ç—Ä–∏–º—É—î—Ç—å—Å—è —É –ø–æ—Ç–æ—á–Ω–æ–º—É SDK
        resp = model.generate_content(
            parts,
            generation_config=generation_config
        )

        text = getattr(resp, "text", "").strip()
        if not text:
            print("‚ö†Ô∏è Vertex AI –Ω–µ –ø–æ–≤–µ—Ä–Ω—É–≤ —Ç–µ–∫—Å—Ç.")
            return None

        return text

    except Exception as e:
        print("‚ùå Vertex AI error:", str(e))
        import traceback
        traceback.print_exc()
        return None
